{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRY7+9XwE03ZnPwJy+uSfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altn714/ESAA/blob/main/22_0919_%EA%B3%BC%EC%A0%9C_p39_86_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvnttYaDdpvG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 핸들링-판다스\n",
        "1. 데이터 처리의 라이브러리\n",
        "2. 행과 열로 이뤄진 2차원 데이터의 효율적인 가공,처리 기능 \n",
        "3. 넘파이보다 유연한 데이터 핸들링 (고수준 API)\n",
        "4. 파이썬(리스트,컬렉션,넘파이 기능) + CSV,tab (*칼럼 분리 파일) 파일을 쉽게 DataFrame으로 변경해 데이터의 가공/분석 편리\n",
        "5. 핵심객체\n",
        "\n",
        "> 1) DataFrame (2차원,칼럼이 여러 개인 데이터 구조체/ 여러 개의 series로 구성)\n",
        "\n",
        "> 2) Index (개별 데이터를 고유하게 식별하는 Key 값)\n",
        "\n",
        "> 3) Series (칼럼이 하나뿐인 데이터 구조체)\n",
        "\n",
        "*Dataframe과 series는 index를 key값으로 가짐\n",
        "___\n",
        "#파일->DataFrame으로 로딩, 기본 API\n",
        "csv 파일 에디터 프로그램으로 열면, \n",
        "맨 위 줄: 칼럼 명,필드 콤마 분리\n",
        "\n",
        "*  read_csv() #칼럼을 , 구분(디폴트) / 탭으로 구분 되어있을 경우: read_csv('파일명',sep='\\t') / 별 지정 없으면 맨 처음 로우를 칼럼명으로 인지함 \n",
        "read_table() #칼럼을 탭('\\t') 구분 \n",
        "\n",
        "=> 주로, read_csv()만 쓸 것\n",
        "\n",
        "*  Filepath\n",
        "\n",
        "> 1) 파일명만 : 파이썬 실행 파일의 디렉터리와 동일한 디렉터리에 있는 파일명 로딩\n",
        "\n",
        "> 2) 파일경로 : 파일명이 포함된 파일경로\n",
        "\n",
        "\n",
        "*  read_fwf() : Fixed Width 고정 길이 기반의 칼럼 포맷을 DataFrame으로 로딩\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8Mpe0CheBO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #판다스를 pd로 임포트"
      ],
      "metadata": {
        "id": "F_8r5q7nn2eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파일명만 : 새로운 주피터 노트북과 titanic_train.csv가 같은 디렉터리 \n",
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "print('titanic 변수 type:', type(titanic_df))\n",
        "titanic_df #호출 시, DataFrame의 모든 데이터를 출력\n",
        "\n",
        "#파일경로\n",
        "titanic_df = pd.read_csv(r'C:\\Users\\chkwon\\Data_Handling\\titanic_train.csv')\n",
        "titanic_df.head(3) #칼럼명 제외 3개의 로우 반환 , 디폴트는 5개임\n",
        "\n",
        "#결과 pd.read_csv() 파일명 인자의 파일을 dataframe객체 반환\n",
        "#첫번째 줄 로우 문자열 = dataframe의 칼럼명으로 할당\n",
        "#콤마 분리\n",
        "#판다스 Index 객체 값:  칼럼명이 없는 로우 순의 데이터 값\n"
      ],
      "metadata": {
        "id": "CAlFrB7-uGtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FbvIYvuopuEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. shape: 데이터프레임의 크기\n",
        "print('DataFrame 크기:', titanic_df.shape) #튜플 형태 반환\n",
        "\n",
        "#2.info()\n",
        "titanic_df.info() #데이터 건수,타입,Null 건수\n",
        "\n",
        "#3.describe() : 데이터 분포도 조사\n",
        "titanic_df.describe() \n",
        "#칼럼별 숫자형 데이터 값의 n-percentile 분포도, 평균값,최댓값, 최솟값\n",
        "#오직 숫자형 (int,float 등) 칼럼의 분포도만 조사하고 object는 제외\n",
        "#해당 숫자 칼럼이 숫자형 카테코리 칼럼인지 판단 cf)남자 1,여자 2\n",
        "# count: Not Null인 데이터 건수/ mean 전체 데이터 평균값/ std 표준편차/min 최솟값/max 최댓값/ 25% 25percentile 값/50%/75% 같음\n",
        "\n"
      ],
      "metadata": {
        "id": "gf53dw6yxXfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_pclass = titanic_df['Pclass']\n",
        "print(type(titanic_pclass)) #[칼럼명] 입력,series 형태로 칼럼 데이터 세트 반환\n",
        "\n",
        "# 숫자형 카테코리 칼럼 분포 확인법 \n",
        "value_counts = titanic_df['Pclass'].value_counts() #칼럼값 유형과 건수 반환,많은 건수 순서 정렬\n",
        "#value_counts() 는 series에만 있음\n",
        "print(type(value counts)) #series 객체 반환\n",
        "print(value_counts) #인덱스가 의미없는 순차 값 아님, 고유성이 보장되면 의미 있는 데이터 값 할당 즉, 고유칼럼 값을 식별자로 사용(인덱스는 숫자형, 문자열 가능 하지만, 모든 인덱스의 고유성 보장)\n"
      ],
      "metadata": {
        "id": "MJBgtmg137ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#series:index와 단 하나의 칼럼 구성된 데이터 세트\n",
        "\n",
        "titanic_pclass.head() #왼쪽의 순차 값(index), series의 해당 칼럼의 데이터 값\n",
        "\n",
        "모든 series와 DataFrame은 인덱스 가짐"
      ],
      "metadata": {
        "id": "HSCyr21f5-XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#상호변환\n",
        "*   파이썬(리스트,딕션너리,넘파이 ndarray) -> dataframe 변환 생성\n",
        "\n",
        "*   DataFrame -> 파이썬(리스트,딕션너리,넘파이 ndarray) 변환 생성\n",
        "\n",
        "*   사이킷런의 API: \n",
        "DataFrame을 인자로 입력 하지만, 기본적으로 넘파이 ndarray를 입력 인자로 사용\n",
        "\n",
        "__DataFrame과 넘파이 ndarray 상호 간 변환 빈번하게 발생__ \n",
        "\n",
        "#DataFrame :칼럼명 있음 (리스트,ndarray와 다른 점)\n"
      ],
      "metadata": {
        "id": "YSPhb9GTYEuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#1차원 형태 데이터, 데이터 프레임 생성 (칼럼명 한 개)\n",
        "col_name1 = ['col1']\n",
        "list1 = [1,2,3] #list 생성\n",
        "array1 = np.array(list1) #array 생성\n",
        "print('array 1 shape:', array1.shape)\n",
        "\n",
        "#리스트를 이용해 DataFrame 생성\n",
        "df_list1 = pd.DataFrame(list1, columns=col_name1) \n",
        "print('1차원 리스트로 만든 DataFrame;\\n', df_list1) \n",
        "#넘파이 ndarray를 이용해 DataFrame 생성\n",
        "df_array1 = pd.DataFrame(array1, colums=col_name1)\n",
        "print('1차원 ndarray로 만든 DataFrame:\\n', df_array1)"
      ],
      "metadata": {
        "id": "1F-duqHsa8_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2차원 형태 데이터(리스트,ndarray), 데이터 프레임 생성 \n",
        "\n",
        "# 3개의 칼럼명 지정 !!\n",
        "col_name2 = ['col1', 'col2', 'col3']\n",
        "\n",
        "#2행X3열 형태 리스트와 ndarray 생성\n",
        "list2 = [[1, 2, 3],\n",
        "         [11, 12, 13]]\n",
        "array2= np.array(list2)\n",
        "print('array2 shape:', array2.shape)\n",
        "\n",
        "df_list2 = pd.DataFrame(list2, columns=col_name2)\n",
        "print('2차원 리스트로 만든:\\n', df_list2)\n",
        "\n",
        "df_array2 = pd.DataFrame(array2, columns2 = col_name2)\n",
        "print('2차원 ndarray로 만든 DataFrame:\\n', df_array2)\n"
      ],
      "metadata": {
        "id": "pq3yVVAxcZyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#딕셔너라 DataFrame로 변환\n",
        "\n",
        "#Key는 문자열 칼럼명으로 매핑, Value는 리스트 형(또는 ndarray) 칼럼 데이터로 매핑\n",
        "dict = {'col1':[1, 11], 'col2':[2, 22], 'col3':[3, 33]}\n",
        "df_dict = pd.DataFrame(dict)\n",
        "print('딕셔너리로 만든 DataFrame:\\n', df_dict)"
      ],
      "metadata": {
        "id": "Ij9pZHBheQ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrame의 변환(ndarray,리스트,딕셔너리)\n",
        ".values() 사용"
      ],
      "metadata": {
        "id": "Ej0qNFsdf1Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrame을 ndarray로 변환\n",
        "array3 = df_dict.values #DataFrame 객체의 values 이용\n",
        "print('df_dict.values 타입:', type(array3), 'df_dict.values shape:', array3.shape)\n",
        "print(array3)\n",
        "\n",
        "#DataFrame을 리스트로 변환\n",
        "list3 = df_dict.values.tolist() #리스트 변환\n",
        "print('df_dict.values.tolist() 타입:', type(list3))\n",
        "print(list3)\n",
        "\n",
        "#DataFrame을 딕셔너리로 변환\n",
        "dict3 = df_dict.to_dict('list') #to_dict() 딕셔너리 변환, 인자로 list 입력 시 딕셔너리의 값이 리스트 형으로 반환\n",
        "print('\\n df_dict.to_dict() 타입:', type(dict3))\n",
        "print(dict3)"
      ],
      "metadata": {
        "id": "bN8jAwymfvt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrame의 칼럼 데이터 세트 생성\n"
      ],
      "metadata": {
        "id": "c731Q9-8hqRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_0']=0 #칼럼 Age_0 추가, 일괄적 0 할당\n",
        "titanic_df.head(3)\n",
        "\n",
        "#칼럼명 'Age_0; 아래 모든 데이터 값이 0으로 할당된 series가 기존 DataFrame에 추가\n",
        "\n",
        "titanic_df['Age_by_10']= titanic_df['Age']*10 \n",
        "titanic_df['Family_No'] = titanic_df['SibSp']+ titanic_df['Parch']+1\n",
        "titanic_df.head(3)\n",
        "\n",
        "titanic_df['Age_by_10'] = titanic_df['Age_by_10']+100 #업데이트 원하는 칼럼 Series를 []내 입력하고 뒤에 값 할당\n",
        "titanic_df.head(3)\n"
      ],
      "metadata": {
        "id": "wA_8OcHfhw9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrame 데이터 삭제, drop()\n",
        "\n",
        "axis=0 로우 축 방향 삭제 *이상치 데이터 삭제\n",
        "\n",
        "axis=1 칼럼 축 방향 삭제 *주로 사용\n"
      ],
      "metadata": {
        "id": "Er5stBfXjwDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# labels, axis 파라미터\n",
        "titanic_drop_df = titanic_df.drop('Age_0', axis=1) #titanic_drop_df 새로운 변수로 반환, Age_0 칼럼 삭제\n",
        "titanic_drop_df.head(3) \n",
        "\n",
        "#inplace 파라미터 (디폴트가 inplace = False)\n",
        "drop_result = titanic_df.drop(['Age_0', 'Age_by_10', 'Family_No', axis=1, inplace=True])\n",
        "#labels에 삭제하고 싶은 칼럼 여러 개 리스트로 넣음, inplace로 설정하면 자신의 DataFrame의 데이터 삭제\n",
        "#drop_result 객체 변수를 아예 None으로 만듦\n",
        "print(' inplace=True로 drop 후 반환된 값:', drop_result) \n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "6EZwJMhylSdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인덱스 0,1,2 로우 삭제\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', 15)\n",
        "print('### before axis 0 drop ###')\n",
        "print(titanic_df.head(3))\n",
        "\n",
        "titanic_df.drop([0, 1, 2], axis=0, inplace=True)\n",
        "print('### after axis 0 drop ###')\n",
        "print(titanic_df.head(3))"
      ],
      "metadata": {
        "id": "PvrkpIUrpTpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Index 객체"
      ],
      "metadata": {
        "id": "rSafB8_IqxUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#원본 파일 다시 로딩\n",
        "titanic_df = pd.read_csv('titanic_train.csv')\n",
        "#index 객체 추출\n",
        "indexes = titanic_df.index\n",
        "print(indexes)\n",
        "#index 객체를 실제 값 array로 변환\n",
        "print('Index 객체 array값:\\n', indexes.values) #1차원 array"
      ],
      "metadata": {
        "id": "3Ak2AlHhrRx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index 객체(식별성 데이터를 1차원 array, ndarray 처럼 단일 값 반환 및 슬라이싱 가능)\n",
        "print(type(indexes.values)) #.values() 니깐 ndarray 반환\n",
        "print(indexes.values.shape)\n",
        "\n",
        "print(indexes[:5].values)\n",
        "print(indexes.values[:5])\n",
        "print(indexes[6])"
      ],
      "metadata": {
        "id": "psZ-wgvgrpFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index 특성\n",
        "\n",
        "한 번 만들어진 DataFrame 및 Series의 Index 객체 변경 못함.\n",
        "\n",
        "series 객체는 Index 객체를 포함하지만, Series 객체에 연산함수를 적용할 때, index는 연산에서 제외 (인덱스는 오직 식별용)"
      ],
      "metadata": {
        "id": "GCHwf7sRtyQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexes[0] = 5 #error\n",
        "\n",
        "series_fair = titanic_df['Fare']\n",
        "print('Fare Series max 값:', series_fair.max())\n",
        "print('Fair Series sum 값:', series_fairn.sum())\n",
        "print('Sum() Fair Series:', sum(series_fair))\n",
        "print('Fair Series + 3:\\n', (series_fair+3).head(3)) #인덱스 연산에서 제외"
      ],
      "metadata": {
        "id": "xiXWOu_yt3w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset_index() \n",
        "#새롭게 인덱스를 연속 숫자형으로 할당, 기존 인덱스는 'index' 새로운 칼럼명 추가\n",
        "titanic_reset_df = titanic_df.reset_index(inplace=False)\n",
        "titanic_reset_df.head(3)\n",
        "\n",
        "# 인덱스를 연속 int 숫자형 데이터로 만들 때\n",
        "# series에 reset_index()를 적용하면 series가 아닌 DataFrame이 반환됨\n",
        "# 칼럼 2개 됨\n",
        "print('### before reset_index ###')\n",
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(value_counts)\n",
        "print('value_counts 객체 변수 타입:', type(value_counts)) #series\n",
        "\n",
        "new_value_counts = value_counts.reset_index(inplace=False) \n",
        "print('### After reset_index ###')\n",
        "print(new_value_counts)\n",
        "print('new_value_counts 객체변수 타입:', type(new_value_counts)) #DataFrame 반환\n",
        "\n",
        "#parameter 중 drop=True로 설정하면 기존 인덱스 새로운 칼럼으로 추가 X, 삭제됨\n",
        "#새로운 칼럼이 추가되지 않으므로 그대로 Series로 유지"
      ],
      "metadata": {
        "id": "7OpxhtxfwAcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 셀렉션 및 필터링\n",
        "DataFrame 뒤에 있는 []는 칼럼만 지정 즉, '칼럼 지정 연산자'\n",
        "\n",
        "titanic_df['칼럼1','칼럼2'] 리스트 객체 이용\n",
        "titanic_df[0] 은 오류 발생 #0이 칼럼명이 아님.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LHOToCN9b1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단일 칼럼 데이터 추출;\\n', titanic_df[ 'Pclass'].head(3))\n",
        "print('\\n여러 칼럼의 데이터 추출;\\n', titanic_df[['survived', 'Pclass']].head(3))\n",
        "print('[] 안에 숫자 index는 Key Error 오류발생:\\n', titanic_df[0])\n",
        "\n",
        "#하지만, 판다스의 인덱스 형태로 변환 가능한 표현식은 []내 입력 가능\n",
        "titanic_df[0:2] #처음 2개 데이터 추출 위한 슬라이싱\n",
        "\n",
        "#Pclass 칼럼 값이 3인 데이터 3개 추출\n",
        "titanic_df[ titanic_df['Pclass']=3].head(3)"
      ],
      "metadata": {
        "id": "IbjcAw-v-_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrame ix[] 연산자\n",
        "#곧 사라짐\n",
        "#첫번째 로우, 두번째 칼럼\n",
        "#단일 값 반환 or 반환값 여러개면, DataFrame으로 반환\n",
        "#지정범위 단일 숫자, 칼럼명 혹은 슬라이싱으로 씀\n",
        "# ':'는  전체 DataFrame 반환\n",
        "\n",
        "#Year 칼럼 값이 2014보다 크거나 같은 로우 인덱스를 가지는 DataFrame 반환\n",
        "data_df.ix[data_df.Year >= 2014]"
      ],
      "metadata": {
        "id": "IWZh4WJG__U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ix 데이터 반환\n",
        "#data_df를 reset_index()로 새로운 숫자형 인덱스 생성 (원래는 문자열이었음)\n",
        "data_df_reset = data_df.reset_index()\n",
        "data_df_reset = data_df_reset.rename(columns = {'index':'old_index'})\n",
        "\n",
        "#인덱스값에 1을 더해서 1부터 시작하는 새로운 인덱스 값 생성\n",
        "data_df_reset.index = data_df_reset.index+1\n",
        "data_df_reset\n",
        "\n",
        "data_df_reset.ix[0,1] #새로 추가된 index 값이 0인 key를 찾을 수 없음 따라서, error\n",
        "data_df_reset.ix[1,1] #첫번째 행 (인덱스값 1)의 2번째 열 위치 데이터 값 반환\n"
      ],
      "metadata": {
        "id": "O_p-huF6D9WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과적으로, DataFrame의 인덱스 값은 명칭 기반 인덱싱으로 간주\n",
        "\n",
        "한계점: 행과 열 위치에 명칭,위치 기반 인덱싱 모두 허용 따라서, 행 위치에 적용되는 인덱스 값과 위치 기반 인덱싱이 integer 형일 때 코드 작성에 혼선 초래\n",
        "\n",
        "따라서, 명칭 기반 인덱싱 연산자 : loc[]\n",
        "위치 기반 인덱싱 연산자 : iloc[] 도입\n",
        "\n"
      ],
      "metadata": {
        "id": "bCJAEdiGFMZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#iloc 위치 기반 인덱싱 (행과 열 값으로 integer ghrdms integer형의 슬라이싱, 팬시 리스트 값 입력)\n",
        "\n",
        "data_df.iloc[0,0] #첫번째 행, 첫번째 열 데이터 추출\n",
        "\n",
        "data_df.iloc[0, 'Name'] #오류\n",
        "data_df.iloc['one',0] #오류\n",
        "\n",
        "data_df_reset.iloc[0,1] #첫번째 행, 두번째 열 위치 반ㄴ환"
      ],
      "metadata": {
        "id": "f_hEkjoRGHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loc[] 명칭 기반 데이터 추출, 행 위치 DataFrame index 값, 열 위치 칼럼명 입력\n",
        "data_Df.loc['one','Name'] #인덱스 값 'one' , 칼럼 명 'name'\n",
        "# index가 숫자 형일 수 있기 때문에 명칭기반이라고 무조건 문자열 입력하는 것은 아님.\n",
        "\n",
        "data_df_reset.loc[1, 'Name'] #행 인덱스 1, 칼럼명 'Name'\n",
        "data_df_reset.loc[0, 'Name'] #행 인덱스 0 없으므로, 오류 반환\n",
        "\n",
        "#주의할 점#\n",
        "# 슬라이싱 '시작값:종료값' 시작값~종료값 *-1 안함. \n",
        "# 명칭 기반 인덱싱의 특성, 숫자가 아니라서 -1 할 수 없음.\n",
        "\n",
        "print('명칭기반 ix slicing\\n', data_df.ix['one': 'two', 'Name'], '\\n')\n",
        "print('위치기반 iloc slicing\\n', data_df.iloc[0:1, 0], '\\n')\n",
        "print('명칭기반 loc slicing\\n', data_df.loc['one': 'two', 'Name'])\n",
        "\n",
        "print(data_df_reset.loc[1:2, 'Name']) #인덱스가 1,2인 2개의 데이터 반환\n",
        "print(data_df.ix[1:2, 'Name']) #위치 기반 인덱싱이 슬라이싱 되면 1:2는 1개의 데이터 반환\n"
      ],
      "metadata": {
        "id": "W5PL6Gd-G6R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#불린 인덱싱\n",
        "*   데이터 필터링 방식\n",
        "\n",
        "*   불링 인덱싱은 [],ix[], loc[] 공통으로 지원\n",
        "\n",
        "*   iloc[]는 정수형 값이 아닌 불린 값에 대해 지원하지 않음."
      ],
      "metadata": {
        "id": "rc1_tjUujslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv('titanic_train.csv') #DataFrame 로드\n",
        "titanic_boolean = titanic_df[titanic_df['Age']>60] #승객 중 나이가 60세 이상인 데이터 추출\n",
        "print(type(titanic_boolean)) #DataFrame 객체 타입\n",
        "titanic_boolean\n",
        "\n",
        "#불링에서 원하는 칼럼만 추출하고 싶은 경우\n",
        "titanic_df[titanic_df['Age']>60][['Name', 'Age']].head(3) #칼럼이 두개 이상이므로 [[]]를 사용, 3개만 추출\n",
        "#loc 이용하는 경우\n",
        "titanic_df.loc[titanic_df['Age']>60, ['Name', 'Age']].head(3) #단, ['Name', 'Age']는 칼럼 위치에 놓여야함."
      ],
      "metadata": {
        "id": "2vRl6Zaak3Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. and 조건 &\n",
        "2. or 조건 |\n",
        "3. Not 조건 ~\n"
      ],
      "metadata": {
        "id": "tE_6rgbNmcCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 조건 나열\n",
        "titanic_df[(titanic_df['Age']> 60) & (titanic_df['Pclass']=1) & (titanic_df['Sex']='female')]\n",
        "\n",
        "#개별 조건 변수 할당 후 변수 결합\n",
        "cond1 = titanic_df['Age']>60\n",
        "cond2 = titanic_df['Pclass']=1\n",
        "cond3 = titanic_df['Sex']= 'female' \n",
        "titanic_df[cond1 & cond2 & cond3]\n",
        "# [],ix[], loc[] 지원됨."
      ],
      "metadata": {
        "id": "LRt-Fx_9mltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#정렬 Aggreagation 함수,GroupBy \n",
        "\n",
        "## 1) DataFrame, Series 정렬-sort_values()\n",
        "*   입력 파라미터: \n",
        "> by (특정 칼럼 입력 시, 해당 칼럼 정렬 수행)\n",
        "\n",
        "> ascending=True 오름차순 (디폴트)/ ascending=False 내림차순 정렬\n",
        "\n",
        "> inplace = False *sort_values()를 호출한 DataFrame은 그대로 유지하며 정렬된 DataFrame 반환 (디폴트) / inplace = True 호출한 DataFrame의 정렬 결과를 그대로 적용\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b05Y8dw1nZDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(칼럼 한 개) titanic_df를 Name 칼럼으로 오름차순 정렬 반환 \n",
        "titanic_sorted = titanic_df.sort_values(by=['Name'])\n",
        "titanic_sorted.head(3)\n",
        "\n",
        "#(칼럼 두 개) Pclass와 Name을 내림차순으로 정렬 반환\n",
        "titanic_sorted = titanic_df.sort_values(by=['Pclass', 'Name'], ascending=False)\n",
        "#칼럼 두 개 일 경우, 리스트 형식으로 [] 칼럼명 적기\n",
        "titanic_sorted.head(3) "
      ],
      "metadata": {
        "id": "G4Fw5sdHoqn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) Aggregation 함수 적용\n",
        "*   min(), max(), sum(), count() 와 같은 aggregation 함수 적용\n",
        "*   DataFrame에서 바로 aggregation을 호출할 경우 모든 칼럼에 해당 aggregation을 적용함.\n",
        "\n",
        "하지만, count()를 적용하면  모든 칼럼에 count()결과 반환\n",
        "\n"
      ],
      "metadata": {
        "id": "18WMXH9LpbFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count 적용\n",
        "titanic_df.count()\n",
        "\n",
        "#mean 적용\n",
        "titanic_df[['Age', 'Fare']].mean() #DataFrame에 대상 칼럼만 추출하여 aggregation 적용\n"
      ],
      "metadata": {
        "id": "ZpM0dXFDp4yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) groupby() 적용\n"
      ],
      "metadata": {
        "id": "YU6Echijq-ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_groupby = titanic_df.groupby(by='Pclass') Pclass 칼럼 기준의 groupby\n",
        "print(type(titanic_groupby)) #DataFrameGroupBy라는 또 다른 형태의 DataFrame 반환\n",
        "\n",
        "#DataFrame에 groupby()를 호출한 결과에 aggregation 함수 호출\n",
        "titanic_groupby = titanic_df.groupby('Pclass').count() #groupby() 대상 칼럼을 제외한 모든 칼럼에 aggregation 함수 적용\n",
        "titanic_groupby"
      ],
      "metadata": {
        "id": "ebtq7zdzrLmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL의 경우 group by 적용 시, 여러 개의 칼럼에 aggregation 함수 호출하려면 대상 칼럼을 모두 Select 절 나열\n",
        "\n",
        "Select count(Passenger), count(Survived), ... from titanic_table group by Pclass \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RwpatpWnt5W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DataFrame의 groupby()에 특정 칼럼만 aggregation 함수를 적용\n",
        "titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId', 'Survived']].count()\n",
        "#titanic_df.groupby('Pclass')로 반환된 DataFrameGroupBy 객체에 [['Passenger', 'Survived']]로 \n",
        "#필터링하고 PassengerId와 Survived 칼럼에만 count() 수행\n",
        "titanic_groupby\n",
        "\n",
        "#(한 개 칼럼) SQL의 groupby\n",
        "Select max(Age), min(Age) from titanic_table groupby Pclass\n",
        "#(한 개 칼럼) 판다스 groupby\n",
        "titanic_df.groupby('Pclass')['Age'].agg([max, min])\n",
        "\n",
        "#(여러개 칼럼) SQL의 groupby\n",
        "Select max(Age), sum(Sibsp), avg(Fare) from titanic_table group by Pclass\n",
        "#(여러개 칼럼) 판다스 groupby (복잡함) \n",
        "#agg()를 이용한 처리, 입력 값으로 딕셔너리 형태로 aggregation이 적용될 칼럼들과 aggregation 함수 입력\n",
        "agg_format= {'Age':'max', 'Sibsp':'sum', 'Fare':'mean'}\n",
        "titanic_df.groupby('Pclass').agg(agg_format)\n",
        "\n"
      ],
      "metadata": {
        "id": "wUpjGd2mulrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#결손 데이터 처리\n",
        "*   결손 데이터 : 칼럼에 값이 없는 Null, 이를 넘파이의 NaN로 표시\n",
        "\n",
        "*   머신러닝 알고리즘은 NaN 값 처리 안함. 따라서, 다른 값 대체 필요\n",
        "\n",
        "*   함수 연산 시 제외\n",
        "\n"
      ],
      "metadata": {
        "id": "L9J6oo_oyEuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#결손 데이터 확인 isna() \n",
        "#모든 칼럼의 값이 NaN인지 아닌지 True 또는 False로 알려줌.\n",
        "titanic_df.isna().head(3)\n",
        "\n",
        "#결손데이터의 갯수 isna() 결과에 sum() 함수 추가\n",
        "# True 숫자 1, False 숫자 0 변환 ->  결손 데이터 갯수 구함\n",
        "titanic_df.isna().sum()\n",
        "\n",
        "#결손 데이터 대체 fillna()\n",
        "titanic_df['Cabin'] = titanic_df['Cabin'].fillna('C000') #타이타닉 데이터 세트의 'Cabin' 칼럼의 NaN값을 'C000'으로 대체\n",
        "titanic_df.head(3) \n",
        "# 실제 데이터 세트 값 변경\n",
        "titanic_df['Cabin']= titanic_df['Cabin'].fillna('C000') \n",
        "#또는\n",
        "titanic_df['Cabin'].fillna('C000', inplace=Ture)\n",
        "\n",
        "titanic_df['Age']=titanic_df['Age'].fillna(titanic_df['Age'].mean()) #Age 카럼의 NaN 값을 평균 나이\n",
        "titanic_df['Embarked']=titanic_df['Embarked'].fillna('S') #Embarked 칼럼의 NaN 값을 S로 대체\n",
        "titanic_df.isna().sum()"
      ],
      "metadata": {
        "id": "cbmjAxsCyj0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#apply 함수에 lambda 식을 결합\n",
        "*   DataFrame이나 Series의 레코드별로 데이터 가공\n",
        "\n",
        "*  lambda 식은 파이썬에서 함수형 프로그래밍을 지원하기 위해 만들어짐.\n",
        "\n"
      ],
      "metadata": {
        "id": "ojeom3L-3euy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_square(a): #함수명과 입력 인자 선언\n",
        "  return a**2 #결과값 반환\n",
        "\n",
        "print('3의 제곱은:', get_square(3))\n",
        "\n",
        "#lambda 식 변환 (하나의 입력인자)\n",
        "lambda_squre = lambda x : x ** 2 #':' 왼쪽에 있는 x는 입력 인자, 오른쪽은 입력인자의 계산식(반환값)\n",
        "print('3의 제곱은:', lambda_square(3))\n",
        "\n",
        "#lambda 식 변환 (여러개 입력인자) - map() 사용\n",
        "a=[1, 2, 3]\n",
        "squares = map(lambda x : x**2, a)\n",
        "list(squares)\n",
        "\n",
        "titanic_df['Name_len']=titanic_df['Name'].apply(lambda x : len(x)) \n",
        "#DataFrame의 apply에 lambda 식을 적용, 'Name' 칼럼의 문자열 개수를 별도의 칼럼인 'Name_len'에 생성\n",
        "titanic_df['Name_len']=titanic_df['Name'].apply(lamnda x : len(x))\n",
        "titanic_df[['Name', 'Name_len']].head(3)\n",
        "\n",
        "#lambda 식의 if else 지원\n",
        "titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x : 'child' if x <= 15 else 'Adult')\n",
        "titanic_df[['Age', 'Child_Adult']].head(8)\n",
        "#주의할 점: ':' 오른쪽에 child라는 반환값 먼저 기술, else 식 뒤에 반환값 나중에 옴\n"
      ],
      "metadata": {
        "id": "qNIv2Bhy4HSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if,else만 지원\n",
        "if, else if, else 지원하지 않음\n",
        "\n"
      ],
      "metadata": {
        "id": "pYidwfWp7QAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lamda x : 'Child' if x<=15 else ('Adult' if <= 60 else 'Elderly'))\n",
        "\n",
        "titanic_df['Age_cat'].value_counts() \n",
        "\n",
        "#else 내포로 계속 쓰기 부담스러우면 -> 별도 함수 생성\n",
        "#나이에 따라 세분화된 분류를 수행하는 함수 생성\n",
        "def get_category(age):\n",
        "  cat = ''\n",
        "  if age <= 5: cat = 'Baby'\n",
        "  elif age <= 12: cat = 'Child'\n",
        "  elif age <= 18: cat = 'Teenager'\n",
        "  elif age <= 25: cat = 'Student'\n",
        "  elif age <= 35: cat = 'Young Adult'\n",
        "  elif age <= 60: cat = 'Adult'\n",
        "  else : cat ='Elderly'\n",
        "\n",
        "  return cat\n",
        "\n",
        "  #lambda 식에 위에서 생성한 get_category() 함수를 반환값 지정\n",
        "  # get_category(X)는 입력값으로 'Age' 칼럼 값을 받아서 해당하는 cat 반환\n",
        "\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x :get_category(x))\n",
        "titanic_df[['Age', 'Age_cat']].head()"
      ],
      "metadata": {
        "id": "I73iXgs97RIT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}